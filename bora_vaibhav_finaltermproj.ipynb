{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9cb14f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Random Forest Classifier Metrics:\n",
      "           TP     TN    FP    FN  Accuracy  Sensitivity (TPR)  \\\n",
      "Fold 1   10.0  391.0   9.0  43.0  0.885210           0.188679   \n",
      "Fold 2   10.0  392.0   8.0  42.0  0.889381           0.192308   \n",
      "Fold 3   10.0  391.0   9.0  42.0  0.887168           0.192308   \n",
      "Fold 4   10.0  391.0   9.0  42.0  0.887168           0.192308   \n",
      "Fold 5    4.0  396.0   4.0  48.0  0.884956           0.076923   \n",
      "Fold 6    9.0  395.0   5.0  43.0  0.893805           0.173077   \n",
      "Fold 7   11.0  397.0   3.0  41.0  0.902655           0.211538   \n",
      "Fold 8    6.0  396.0   4.0  46.0  0.889381           0.115385   \n",
      "Fold 9   10.0  388.0  12.0  42.0  0.880531           0.192308   \n",
      "Fold 10  11.0  392.0   8.0  41.0  0.891593           0.211538   \n",
      "Average   9.1  392.9   7.1  43.0  0.889185           0.174637   \n",
      "\n",
      "         Specificity (TNR)  Precision  F1 Score  Error Rate  \\\n",
      "Fold 1             0.97750   0.526316  0.277778    0.114790   \n",
      "Fold 2             0.98000   0.555556  0.285714    0.110619   \n",
      "Fold 3             0.97750   0.526316  0.281690    0.112832   \n",
      "Fold 4             0.97750   0.526316  0.281690    0.112832   \n",
      "Fold 5             0.99000   0.500000  0.133333    0.115044   \n",
      "Fold 6             0.98750   0.642857  0.272727    0.106195   \n",
      "Fold 7             0.99250   0.785714  0.333333    0.097345   \n",
      "Fold 8             0.99000   0.600000  0.193548    0.110619   \n",
      "Fold 9             0.97000   0.454545  0.270270    0.119469   \n",
      "Fold 10            0.98000   0.578947  0.309859    0.108407   \n",
      "Average            0.98225   0.569657  0.263994    0.110815   \n",
      "\n",
      "         Balanced Accuracy (BACC)      FPR       FNR  Brier Score (BS)  \\\n",
      "Fold 1                   0.583090  0.02250  0.811321          0.080369   \n",
      "Fold 2                   0.586154  0.02000  0.807692          0.082087   \n",
      "Fold 3                   0.584904  0.02250  0.807692          0.081918   \n",
      "Fold 4                   0.584904  0.02250  0.807692          0.077802   \n",
      "Fold 5                   0.533462  0.01000  0.923077          0.069704   \n",
      "Fold 6                   0.580288  0.01250  0.826923          0.073226   \n",
      "Fold 7                   0.602019  0.00750  0.788462          0.069093   \n",
      "Fold 8                   0.552692  0.01000  0.884615          0.082322   \n",
      "Fold 9                   0.581154  0.03000  0.807692          0.080602   \n",
      "Fold 10                  0.595769  0.02000  0.788462          0.071348   \n",
      "Average                  0.578444  0.01775  0.825363          0.076847   \n",
      "\n",
      "         Brier Skill Score (BSS)       AUC       HSS       TSS  \n",
      "Fold 1                  0.222059  0.844858  0.230246  0.166179  \n",
      "Fold 2                  0.193717  0.840240  0.240795  0.172308  \n",
      "Fold 3                  0.195380  0.850625  0.234560  0.169808  \n",
      "Fold 4                  0.235800  0.887596  0.234560  0.169808  \n",
      "Fold 5                  0.315341  0.910865  0.105904  0.066923  \n",
      "Fold 6                  0.280750  0.877837  0.235410  0.160577  \n",
      "Fold 7                  0.321347  0.899904  0.299126  0.204038  \n",
      "Fold 8                  0.191406  0.852356  0.162467  0.105385  \n",
      "Fold 9                  0.208303  0.839760  0.216688  0.162308  \n",
      "Fold 10                 0.299200  0.909856  0.264577  0.191538  \n",
      "Average                 0.246330  0.871390  0.222433  0.156887  \n",
      "\n",
      "Average Values Among All Folds:\n",
      "TP                            9.100000\n",
      "TN                          392.900000\n",
      "FP                            7.100000\n",
      "FN                           43.000000\n",
      "Accuracy                      0.889185\n",
      "Sensitivity (TPR)             0.174637\n",
      "Specificity (TNR)             0.982250\n",
      "Precision                     0.569657\n",
      "F1 Score                      0.263994\n",
      "Error Rate                    0.110815\n",
      "Balanced Accuracy (BACC)      0.578444\n",
      "FPR                           0.017750\n",
      "FNR                           0.825363\n",
      "Brier Score (BS)              0.076847\n",
      "Brier Skill Score (BSS)       0.246330\n",
      "AUC                           0.871390\n",
      "HSS                           0.222433\n",
      "TSS                           0.156887\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "SVM Metrics:\n",
      "           TP     TN    FP    FN  Accuracy  Sensitivity (TPR)  \\\n",
      "Fold 1   10.0  391.0   9.0  43.0  0.885210           0.188679   \n",
      "Fold 2   10.0  392.0   8.0  42.0  0.889381           0.192308   \n",
      "Fold 3   10.0  391.0   9.0  42.0  0.887168           0.192308   \n",
      "Fold 4   10.0  391.0   9.0  42.0  0.887168           0.192308   \n",
      "Fold 5    4.0  396.0   4.0  48.0  0.884956           0.076923   \n",
      "Fold 6    9.0  395.0   5.0  43.0  0.893805           0.173077   \n",
      "Fold 7   11.0  397.0   3.0  41.0  0.902655           0.211538   \n",
      "Fold 8    6.0  396.0   4.0  46.0  0.889381           0.115385   \n",
      "Fold 9   10.0  388.0  12.0  42.0  0.880531           0.192308   \n",
      "Fold 10  11.0  392.0   8.0  41.0  0.891593           0.211538   \n",
      "Average   9.1  392.9   7.1  43.0  0.889185           0.174637   \n",
      "\n",
      "         Specificity (TNR)  Precision  F1 Score  Error Rate  \\\n",
      "Fold 1             0.97750   0.526316  0.277778    0.114790   \n",
      "Fold 2             0.98000   0.555556  0.285714    0.110619   \n",
      "Fold 3             0.97750   0.526316  0.281690    0.112832   \n",
      "Fold 4             0.97750   0.526316  0.281690    0.112832   \n",
      "Fold 5             0.99000   0.500000  0.133333    0.115044   \n",
      "Fold 6             0.98750   0.642857  0.272727    0.106195   \n",
      "Fold 7             0.99250   0.785714  0.333333    0.097345   \n",
      "Fold 8             0.99000   0.600000  0.193548    0.110619   \n",
      "Fold 9             0.97000   0.454545  0.270270    0.119469   \n",
      "Fold 10            0.98000   0.578947  0.309859    0.108407   \n",
      "Average            0.98225   0.569657  0.263994    0.110815   \n",
      "\n",
      "         Balanced Accuracy (BACC)      FPR       FNR  Brier Score (BS)  \\\n",
      "Fold 1                   0.583090  0.02250  0.811321          0.080369   \n",
      "Fold 2                   0.586154  0.02000  0.807692          0.082087   \n",
      "Fold 3                   0.584904  0.02250  0.807692          0.081918   \n",
      "Fold 4                   0.584904  0.02250  0.807692          0.077802   \n",
      "Fold 5                   0.533462  0.01000  0.923077          0.069704   \n",
      "Fold 6                   0.580288  0.01250  0.826923          0.073226   \n",
      "Fold 7                   0.602019  0.00750  0.788462          0.069093   \n",
      "Fold 8                   0.552692  0.01000  0.884615          0.082322   \n",
      "Fold 9                   0.581154  0.03000  0.807692          0.080602   \n",
      "Fold 10                  0.595769  0.02000  0.788462          0.071348   \n",
      "Average                  0.578444  0.01775  0.825363          0.076847   \n",
      "\n",
      "         Brier Skill Score (BSS)       AUC       HSS       TSS  \n",
      "Fold 1                  0.222059  0.844858  0.230246  0.166179  \n",
      "Fold 2                  0.193717  0.840240  0.240795  0.172308  \n",
      "Fold 3                  0.195380  0.850625  0.234560  0.169808  \n",
      "Fold 4                  0.235800  0.887596  0.234560  0.169808  \n",
      "Fold 5                  0.315341  0.910865  0.105904  0.066923  \n",
      "Fold 6                  0.280750  0.877837  0.235410  0.160577  \n",
      "Fold 7                  0.321347  0.899904  0.299126  0.204038  \n",
      "Fold 8                  0.191406  0.852356  0.162467  0.105385  \n",
      "Fold 9                  0.208303  0.839760  0.216688  0.162308  \n",
      "Fold 10                 0.299200  0.909856  0.264577  0.191538  \n",
      "Average                 0.246330  0.871390  0.222433  0.156887  \n",
      "\n",
      "Average Values Among All Folds:\n",
      "TP                            9.100000\n",
      "TN                          392.900000\n",
      "FP                            7.100000\n",
      "FN                           43.000000\n",
      "Accuracy                      0.889185\n",
      "Sensitivity (TPR)             0.174637\n",
      "Specificity (TNR)             0.982250\n",
      "Precision                     0.569657\n",
      "F1 Score                      0.263994\n",
      "Error Rate                    0.110815\n",
      "Balanced Accuracy (BACC)      0.578444\n",
      "FPR                           0.017750\n",
      "FNR                           0.825363\n",
      "Brier Score (BS)              0.076847\n",
      "Brier Skill Score (BSS)       0.246330\n",
      "AUC                           0.871390\n",
      "HSS                           0.222433\n",
      "TSS                           0.156887\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "LSTM Metrics:\n",
      "           TP     TN    FP    FN  Accuracy  Sensitivity (TPR)  \\\n",
      "Fold 1   10.0  391.0   9.0  43.0  0.885210           0.188679   \n",
      "Fold 2   10.0  392.0   8.0  42.0  0.889381           0.192308   \n",
      "Fold 3   10.0  391.0   9.0  42.0  0.887168           0.192308   \n",
      "Fold 4   10.0  391.0   9.0  42.0  0.887168           0.192308   \n",
      "Fold 5    4.0  396.0   4.0  48.0  0.884956           0.076923   \n",
      "Fold 6    9.0  395.0   5.0  43.0  0.893805           0.173077   \n",
      "Fold 7   11.0  397.0   3.0  41.0  0.902655           0.211538   \n",
      "Fold 8    6.0  396.0   4.0  46.0  0.889381           0.115385   \n",
      "Fold 9   10.0  388.0  12.0  42.0  0.880531           0.192308   \n",
      "Fold 10  11.0  392.0   8.0  41.0  0.891593           0.211538   \n",
      "Average   9.1  392.9   7.1  43.0  0.889185           0.174637   \n",
      "\n",
      "         Specificity (TNR)  Precision  F1 Score  Error Rate  \\\n",
      "Fold 1             0.97750   0.526316  0.277778    0.114790   \n",
      "Fold 2             0.98000   0.555556  0.285714    0.110619   \n",
      "Fold 3             0.97750   0.526316  0.281690    0.112832   \n",
      "Fold 4             0.97750   0.526316  0.281690    0.112832   \n",
      "Fold 5             0.99000   0.500000  0.133333    0.115044   \n",
      "Fold 6             0.98750   0.642857  0.272727    0.106195   \n",
      "Fold 7             0.99250   0.785714  0.333333    0.097345   \n",
      "Fold 8             0.99000   0.600000  0.193548    0.110619   \n",
      "Fold 9             0.97000   0.454545  0.270270    0.119469   \n",
      "Fold 10            0.98000   0.578947  0.309859    0.108407   \n",
      "Average            0.98225   0.569657  0.263994    0.110815   \n",
      "\n",
      "         Balanced Accuracy (BACC)      FPR       FNR  Brier Score (BS)  \\\n",
      "Fold 1                   0.583090  0.02250  0.811321          0.080369   \n",
      "Fold 2                   0.586154  0.02000  0.807692          0.082087   \n",
      "Fold 3                   0.584904  0.02250  0.807692          0.081918   \n",
      "Fold 4                   0.584904  0.02250  0.807692          0.077802   \n",
      "Fold 5                   0.533462  0.01000  0.923077          0.069704   \n",
      "Fold 6                   0.580288  0.01250  0.826923          0.073226   \n",
      "Fold 7                   0.602019  0.00750  0.788462          0.069093   \n",
      "Fold 8                   0.552692  0.01000  0.884615          0.082322   \n",
      "Fold 9                   0.581154  0.03000  0.807692          0.080602   \n",
      "Fold 10                  0.595769  0.02000  0.788462          0.071348   \n",
      "Average                  0.578444  0.01775  0.825363          0.076847   \n",
      "\n",
      "         Brier Skill Score (BSS)       AUC       HSS       TSS  \n",
      "Fold 1                  0.222059  0.844858  0.230246  0.166179  \n",
      "Fold 2                  0.193717  0.840240  0.240795  0.172308  \n",
      "Fold 3                  0.195380  0.850625  0.234560  0.169808  \n",
      "Fold 4                  0.235800  0.887596  0.234560  0.169808  \n",
      "Fold 5                  0.315341  0.910865  0.105904  0.066923  \n",
      "Fold 6                  0.280750  0.877837  0.235410  0.160577  \n",
      "Fold 7                  0.321347  0.899904  0.299126  0.204038  \n",
      "Fold 8                  0.191406  0.852356  0.162467  0.105385  \n",
      "Fold 9                  0.208303  0.839760  0.216688  0.162308  \n",
      "Fold 10                 0.299200  0.909856  0.264577  0.191538  \n",
      "Average                 0.246330  0.871390  0.222433  0.156887  \n",
      "\n",
      "Average Values Among All Folds:\n",
      "TP                            9.100000\n",
      "TN                          392.900000\n",
      "FP                            7.100000\n",
      "FN                           43.000000\n",
      "Accuracy                      0.889185\n",
      "Sensitivity (TPR)             0.174637\n",
      "Specificity (TNR)             0.982250\n",
      "Precision                     0.569657\n",
      "F1 Score                      0.263994\n",
      "Error Rate                    0.110815\n",
      "Balanced Accuracy (BACC)      0.578444\n",
      "FPR                           0.017750\n",
      "FNR                           0.825363\n",
      "Brier Score (BS)              0.076847\n",
      "Brier Skill Score (BSS)       0.246330\n",
      "AUC                           0.871390\n",
      "HSS                           0.222433\n",
      "TSS                           0.156887\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Time taken to output: 103.74 seconds\n"
     ]
    }
   ],
   "source": [
    "# Importing all the necessary libraries for the code to run smoothly\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, brier_score_loss, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import time\n",
    "\n",
    "# Using the time library to calculate and output the total time the code took loading\n",
    "\n",
    "# Starting time\n",
    "start_time = time.time()\n",
    "\n",
    "# Loading the bank dataset\n",
    "Bank_Dataset = pd.read_csv(\"bank.csv\", delimiter=';')\n",
    "\n",
    "# Mentioning the different columns from the dataset\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    Bank_Dataset[col] = le.fit_transform(Bank_Dataset[col].astype(str))\n",
    "\n",
    "# Target variable 'y' is the output and it is in a binary classification of either 'yes' or 'no'\n",
    "# Converting the target variable from categorical strings to binary format (1 for 'yes' and 0 for 'no')\n",
    "# This helps in the usage of mathematical calculations in the code further down\n",
    "Bank_Dataset['y'] = Bank_Dataset['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# The below code is fundamental step for data prep and is splitting the dataset into features and target variable\n",
    "X = Bank_Dataset.drop('y', axis=1)\n",
    "y = Bank_Dataset['y']\n",
    "\n",
    "# Standardizing sets\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_reshaped = np.reshape(X_scaled, (X_scaled.shape[0], 1, X_scaled.shape[1]))  # This reshaped one is for the LSTM algorithm\n",
    "\n",
    "# Setting up for the k-fold cross-validation making sure that there is balanced sampling\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Creating an empty list for all three algorithms to store the output of each fold\n",
    "rf_metrics = []\n",
    "svm_metrics = []\n",
    "lstm_metrics = []\n",
    "\n",
    "# Defining the LSTM model using input layer alongside input shape\n",
    "def create_lstm_model(shape_input):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=shape_input)) # Defining the shape\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True)) # Setting return sequence to True\n",
    "    model.add(Dropout(0.2)) # Drouput helps out with regularization\n",
    "    model.add(LSTM(20, activation='relu')) # Another layer\n",
    "    model.add(Dense(1, activation='sigmoid')) # Helping with the binary classification\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # Compilation\n",
    "    return model\n",
    "\n",
    "# Cross-validation loop for each of the three algorithms\n",
    "for train_index, test_index in kf.split(X_scaled, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index] # Splitting into training and testing sets\n",
    "    X_train_reshaped, X_test_reshaped = X_reshaped[train_index], X_reshaped[test_index] # LSTM exclusive\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Random Forest Classifier training and prediction\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    y_pred_rf_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # SVM Classifier training and prediction\n",
    "    svm = SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred_svm = svm.predict(X_test)\n",
    "    y_pred_svm_proba = svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # LSTM Classifier training and prediction\n",
    "    lstm_model = create_lstm_model((X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "    lstm_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=64, verbose=0)\n",
    "    y_pred_lstm = (lstm_model.predict(X_test_reshaped) > 0.5).astype(int)\n",
    "    y_pred_lstm_proba = lstm_model.predict(X_test_reshaped).flatten()\n",
    "    \n",
    "    # Now we will be inputting the confusion matrix and formulas for each algorithm\n",
    "    # Below we are solving the confusion matrix in order to calculate accuracy variables i.e. TP, TN, FP, FN for Random Forest\n",
    "    conf_matr_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "    TN = conf_matr_rf[0, 0]\n",
    "    FP = conf_matr_rf[0, 1]\n",
    "    FN = conf_matr_rf[1, 0]\n",
    "    TP = conf_matr_rf[1, 1]\n",
    "    \n",
    "    # Jotting down all the important formulas needed for the output calculations for Random Forest\n",
    "    Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    TPR = TP/(TP+FN)  # Sensitivity\n",
    "    TNR = TN/(TN+FP)  # Specificity\n",
    "    Precision = TP/(TP+FP)\n",
    "    F1_Score = 2*(Precision*TPR)/(Precision+TPR)\n",
    "    Error_Rate = (FP+FN)/(TP+TN+FP+FN)\n",
    "    BACC = (TPR+TNR)/2\n",
    "    FPR = FP/(FP+TN)\n",
    "    FNR = FN/(TP+FN)\n",
    "    TSS = TPR-FPR\n",
    "    BS = brier_score_loss(y_test, y_pred_rf_proba)\n",
    "    BSS = 1-BS/np.var(y_test)\n",
    "    AUC = roc_auc_score(y_test, y_pred_rf_proba)\n",
    "    HSS = 2*(TP*TN-FP*FN)/((TP+FN)*(FN+TN)+(TP+FP)*(FP+TN))\n",
    "    \n",
    "    # Below we are solving the confusion matrix in order to calculate accuracy variables i.e. TP, TN, FP, FN for SVM\n",
    "    conf_matr_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "    TN = conf_matr_svm[0, 0]\n",
    "    FP = conf_matr_svm[0, 1]\n",
    "    FN = conf_matr_svm[1, 0]\n",
    "    TP = conf_matr_svm[1, 1]\n",
    "    \n",
    "    # Jotting down all the important formulas needed for the output calculations for SVM\n",
    "    Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    TPR = TP/(TP+FN)  # Sensitivity\n",
    "    TNR = TN/(TN+FP)  # Specificity\n",
    "    Precision = TP/(TP+FP)\n",
    "    F1_Score = 2*(Precision*TPR)/(Precision+TPR)\n",
    "    Error_Rate = (FP+FN)/(TP+TN+FP+FN)\n",
    "    BACC = (TPR+TNR)/2\n",
    "    FPR = FP/(FP+TN)\n",
    "    FNR = FN/(TP+FN)\n",
    "    TSS = TPR-FPR\n",
    "    BS = brier_score_loss(y_test, y_pred_svm_proba)\n",
    "    BSS = 1-BS/np.var(y_test)\n",
    "    AUC = roc_auc_score(y_test, y_pred_svm_proba)\n",
    "    HSS = 2*(TP*TN-FP*FN)/((TP+FN)*(FN+TN)+(TP+FP)*(FP+TN))\n",
    "    \n",
    "    # Below we are solving the confusion matrix in order to calculate accuracy variables i.e. TP, TN, FP, FN for LSTM\n",
    "    conf_matr_lstm = confusion_matrix(y_test, y_pred_lstm) # LSTM Confusion Matrix\n",
    "    TN = conf_matr_lstm[0, 0]\n",
    "    FP = conf_matr_lstm[0, 1]\n",
    "    FN = conf_matr_lstm[1, 0]\n",
    "    TP = conf_matr_lstm[1, 1]\n",
    "    \n",
    "    # Jotting down all the important formulas needed for the output calculations for LSTM\n",
    "    Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    TPR = TP/(TP+FN)  # Sensitivity\n",
    "    TNR = TN/(TN+FP)  # Specificity\n",
    "    Precision = TP/(TP+FP) if(TP+FP)!=0 else 0\n",
    "    F1_Score = 2*(Precision*TPR)/(Precision+TPR) if(Precision+TPR)>0 else 0 # Here I set this if statement because sometimes it was giving an error for diving by 0\n",
    "    Error_Rate = (FP+FN)/(TP+TN+FP+FN)\n",
    "    BACC = (TPR+TNR)/2\n",
    "    FPR = FP/(FP+TN)\n",
    "    FNR = FN/(TP+FN)\n",
    "    TSS = TPR-FPR\n",
    "    BS = brier_score_loss(y_test, y_pred_lstm_proba)\n",
    "    BSS = 1-BS/np.var(y_test)\n",
    "    AUC = roc_auc_score(y_test, y_pred_lstm_proba)\n",
    "    HSS = 2*(TP*TN-FP*FN)/((TP+FN)*(FN+TN)+(TP+FP)*(FP+TN))\n",
    "    \n",
    "    # Using the append feature to add the variables to the list with the values of Random Forest\n",
    "    rf_metrics.append({\n",
    "        'TP': TP,\n",
    "        'TN': TN,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'Accuracy': Accuracy,\n",
    "        'Sensitivity (TPR)': TPR,\n",
    "        'Specificity (TNR)': TNR,\n",
    "        'Precision': Precision,\n",
    "        'F1 Score': F1_Score,\n",
    "        'Error Rate': Error_Rate,\n",
    "        'Balanced Accuracy (BACC)': BACC,\n",
    "        'FPR': FPR,\n",
    "        'FNR': FNR,\n",
    "        'Brier Score (BS)': BS,\n",
    "        'Brier Skill Score (BSS)': BSS,\n",
    "        'AUC': AUC,\n",
    "        'HSS': HSS,\n",
    "        'TSS': TSS\n",
    "    })\n",
    "    # Using the append feature to add the variables to the list with the values of SVM\n",
    "    svm_metrics.append({\n",
    "        'TP': TP,\n",
    "        'TN': TN,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'Accuracy': Accuracy,\n",
    "        'Sensitivity (TPR)': TPR,\n",
    "        'Specificity (TNR)': TNR,\n",
    "        'Precision': Precision,\n",
    "        'F1 Score': F1_Score,\n",
    "        'Error Rate': Error_Rate,\n",
    "        'Balanced Accuracy (BACC)': BACC,\n",
    "        'FPR': FPR,\n",
    "        'FNR': FNR,\n",
    "        'Brier Score (BS)': BS,\n",
    "        'Brier Skill Score (BSS)': BSS,\n",
    "        'AUC': AUC,\n",
    "        'HSS': HSS,\n",
    "        'TSS': TSS\n",
    "    })\n",
    "    # Using the append feature to add the variables to the list with the values of LSTM\n",
    "    lstm_metrics.append({\n",
    "        'TP': TP,\n",
    "        'TN': TN,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'Accuracy': Accuracy,\n",
    "        'Sensitivity (TPR)': TPR,\n",
    "        'Specificity (TNR)': TNR,\n",
    "        'Precision': Precision,\n",
    "        'F1 Score': F1_Score,\n",
    "        'Error Rate': Error_Rate,\n",
    "        'Balanced Accuracy (BACC)': BACC,\n",
    "        'FPR': FPR,\n",
    "        'FNR': FNR,\n",
    "        'Brier Score (BS)': BS,\n",
    "        'Brier Skill Score (BSS)': BSS,\n",
    "        'AUC': AUC,\n",
    "        'HSS': HSS,\n",
    "        'TSS': TSS\n",
    "    })\n",
    "#------------------------RF--------------------------------------\n",
    "# Finding the average of the variables among all folds of Random Forest\n",
    "avg_rf = {key: np.mean([metrics[key] for metrics in rf_metrics]) for key in rf_metrics[0]}\n",
    "\n",
    "# With the previously calculated values from the folds, we create an empty dataframe and fill it with the metrics\n",
    "rf_metrics_df = pd.DataFrame(rf_metrics)\n",
    "rf_metrics_df.index = [f\"Fold {i+1}\" for i in range(len(rf_metrics))]\n",
    "\n",
    "# Creating an empty dataframe for the average value dataset\n",
    "avg_rf_df = pd.DataFrame([avg_rf], index=[\"Average\"])\n",
    "\n",
    "# Combining both the dataframes into a single one\n",
    "combined_rf_df = pd.concat([rf_metrics_df, avg_rf_df])\n",
    "\n",
    "# Finding the mean metrics for a seperate table below\n",
    "avg_rf_metrics = rf_metrics_df.mean()\n",
    "\n",
    "# Output the combined Random Forest dataset\n",
    "print(\"Random Forest Classifier Metrics:\")\n",
    "print(combined_rf_df)\n",
    "print(\"\\nAverage Values Among All Folds:\")\n",
    "print(avg_rf_metrics)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#-----------------------SVM--------------------------------------\n",
    "# Finding the average of the variables among all folds of SVM\n",
    "avg_svm = {key: np.mean([metrics[key] for metrics in svm_metrics]) for key in svm_metrics[0]}\n",
    "\n",
    "# With the previously calculated values from the folds, we create an empty dataframe and fill it with the metrics\n",
    "svm_metrics_df = pd.DataFrame(svm_metrics)\n",
    "svm_metrics_df.index = [f\"Fold {i+1}\" for i in range(len(svm_metrics))]\n",
    "\n",
    "# Creating an empty dataframe for the average value dataset\n",
    "avg_svm_df = pd.DataFrame([avg_svm], index=[\"Average\"])\n",
    "\n",
    "# Combining both the dataframes into a single one\n",
    "combined_svm_df = pd.concat([svm_metrics_df, avg_svm_df])\n",
    "\n",
    "# Finding the mean metrics for a seperate table below\n",
    "avg_svm_metrics = svm_metrics_df.mean()\n",
    "\n",
    "# Output the combined SVM dataset\n",
    "print(\"SVM Metrics:\")\n",
    "print(combined_svm_df)\n",
    "print(\"\\nAverage Values Among All Folds:\")\n",
    "print(avg_svm_metrics)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#------------------------LSTM-------------------------------------\n",
    "# Finding the average of the variables among all folds of LSTM\n",
    "avg_lstm = {key: np.mean([metrics[key] for metrics in lstm_metrics]) for key in lstm_metrics[0]}\n",
    "\n",
    "# With the previously calculated values from the folds, we create an empty dataframe and fill it with the metrics\n",
    "lstm_metrics_df = pd.DataFrame(lstm_metrics)\n",
    "lstm_metrics_df.index = [f\"Fold {i+1}\" for i in range(len(lstm_metrics))]\n",
    "\n",
    "# Creating an empty dataframe for the average value dataset\n",
    "avg_lstm_df = pd.DataFrame([avg_lstm], index=[\"Average\"])\n",
    "\n",
    "# Combining both the dataframes into a single one\n",
    "combined_lstm_df = pd.concat([lstm_metrics_df, avg_lstm_df])\n",
    "\n",
    "# Finding the mean metrics for a seperate table below\n",
    "avg_lstm_metrics = lstm_metrics_df.mean()\n",
    "\n",
    "#Output the combined LSTM dataset\n",
    "print(\"LSTM Metrics:\")\n",
    "print(combined_lstm_df)\n",
    "print(\"\\nAverage Values Among All Folds:\")\n",
    "print(avg_lstm_metrics)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Ending time\n",
    "end_time = time.time()\n",
    "total_duration = end_time-start_time # Calculating and determining the total duration it took to output the code\n",
    "print(f\"Time taken to output: {total_duration:.2f} seconds\") # Outputting the total time for complete execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5fb6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
